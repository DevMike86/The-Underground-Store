/v1<!DOCTYPE html>
<html>
<head>
    <title>AI Store Terminal</title>
    <style>
        body { background: #000; color: #fff; font-family: monospace; text-align: center; padding-top: 100px; }
        #light { font-size: 30px; font-weight: bold; text-shadow: 0 0 10px #333; }
        .box { border: 1px solid #333; display: inline-block; padding: 40px; border-radius: 10px; background: #050505; }
    </style>
</head>
<body>

    <div class="box">
        <div id="light">INITIALIZING...</div>
        <div id="debug" style="color: #444; margin-top: 20px; font-size: 10px;">READY</div>
    </div>

    <script>
        // Your current tunnel link
        const base = "https://unadept-elocutionary-ling.ngrok-free.app/v1";

        async function probeAI() {
            const status = document.getElementById('light');
            const debug = document.getElementById('debug');
            
            // We try the two most common paths LM Studio uses
            const paths = ["/v1/models", "/api/v1/models"];
            
            for (let path of paths) {
                try {
                    const res = await fetch(base + path, {
                        method: "GET",
                        headers: { "ngrok-skip-browser-warning": "true" }
                    });

                    if (res.ok) {
                        status.innerText = "SYSTEM: ONLINE";
                        status.style.color = "#00ff00";
                        status.style.textShadow = "0 0 15px #00ff00";
                        debug.innerText = "CONNECTED VIA " + path;
                        return; // Stop once we find the right one!
                    }
                } catch (e) {
                    console.log("Trying next path...");
                }
            }
            
            status.innerText = "SYSTEM: OFFLINE";
            status.style.color = "red";
            debug.innerText = "CHECK LM STUDIO SERVER STATUS";
        }

        probeAI();
        setInterval(probeAI, 10000);
    </script>
</body>
</html>
